# -*- coding: utf-8 -*-
"""Orphacode API Data Analysis Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wh-km6pt6Hc1ugupnW0RpwlsUCsWorAh
"""

!mkdir orphanet_registry
!cd orphanet_registry
!python -m venv venv
!source venv/bin/activate  # (use venv\Scripts\activate on Windows)
!pip install pandas requests sqlalchemy faker matplotlib plotly

# Collecting and extracting the data from the ORPHAcodes API
import requests
import pandas as pd

def fetch_orphanet_entities(lang='EN', limit=200):
    url = f"https://api.orphacode.org/{lang}/ClinicalEntity"
    headers = {
        "apiKey": "******"
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        raise Exception(f"Error fetching data: {response.status_code}")
    data = response.json()
    df = pd.DataFrame(data)
    df = df.head(limit)
    df.to_csv('orphanet_entities.csv', index=False)
    print(f"Saved {len(df)} rare disease records.")
    return df

if __name__ == "__main__":
    df = fetch_orphanet_entities()

df.head()

# Cleaning the dataset
import pandas as pd

df = pd.read_csv("orphanet_entities.csv")

# Performing validation
print("üîç Checking for missing values:")
print(df.isnull().sum())

# Filling missing definitions or marking them as 'Not available'
df['Definition'] = df['Definition'].fillna("Definition not available")

# Standardizing column names
df.columns = df.columns.str.strip().str.replace(" ", "_")

# Ensuring ORPHAcode is integer
df['ORPHAcode'] = df['ORPHAcode'].astype(int)

# Saving the cleaned file
df.to_csv("orphanet_clean.csv", index=False)
print("Cleaned Orphanet data saved.")

# Creating a registry database
from sqlalchemy import create_engine
import pandas as pd

engine = create_engine('sqlite:///endo_ern_registry.db')

df = pd.read_csv("orphanet_clean.csv")
df.to_sql("Rare_Diseases", engine, if_exists="replace", index=False)

print("Loaded rare disease reference data into registry database.")

# Logging actions performed on the dataset
import sqlite3
import datetime

conn = sqlite3.connect("endo_ern_registry.db")
cursor = conn.cursor()

cursor.execute("""
CREATE TABLE IF NOT EXISTS Metadata (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    table_name TEXT,
    records INTEGER,
    last_updated TEXT,
    data_source TEXT
)
""")

records = len(pd.read_csv("orphanet_clean.csv"))
cursor.execute("""
INSERT INTO Metadata (table_name, records, last_updated, data_source)
VALUES (?, ?, ?, ?)
""", ("Rare_Diseases", records, datetime.datetime.now().isoformat(), "Orphanet ORPHAcode API 2025"))

conn.commit()
conn.close()

print("Metadata logged for audit.")

# Checking the log entries
import sqlite3
import pandas as pd

conn = sqlite3.connect("endo_ern_registry.db")
cursor = conn.cursor()

cursor.execute("SELECT * FROM Metadata LIMIT 5") # Limit to show a few entries
metadata_entries = cursor.fetchall()

# Display as a pandas DataFrame for better readability
if metadata_entries:
    df_metadata = pd.DataFrame(metadata_entries, columns=[description[0] for description in cursor.description])
    display(df_metadata)
else:
    print("No metadata entries found.")

conn.close()

# Exporting a csv file of the data registry for visulaizing it on Power BI
import sqlite3
import pandas as pd

# Connect to the database
conn = sqlite3.connect("endo_ern_registry.db")

# Read the Rare_Diseases table
df = pd.read_sql("SELECT * FROM Rare_Diseases", conn)

# Save as CSV
df.to_csv("Rare_Diseases.csv", index=False)

conn.close()
print("Exported Rare_Diseases.csv successfully!")

